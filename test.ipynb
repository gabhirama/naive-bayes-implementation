{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40edebee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=628982370333-kkqj66e4850ij5qm0nr2l4b6a514s23e.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly&state=KQIWjweaUJovPQeomow0OO4S0w7z6T&access_type=offline\n",
      "Found 17 spam messages and 100 ham messages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from gmail_api import fetch_spam_and_ham\n",
    "\n",
    "if os.path.exists('token.json'):\n",
    "    os.remove('token.json')\n",
    "    spam_mails, ham_mails = fetch_spam_and_ham(100)\n",
    "else:\n",
    "    spam_mails, ham_mails = fetch_spam_and_ham(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3a03042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of ham and spam mails: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Type of ham and spam mails: {type(spam_mails)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2a143e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spam mails: 9\n",
      "Number of ham mails: 71\n"
     ]
    }
   ],
   "source": [
    "spam_mails = {msg_id: metadata for msg_id, metadata in spam_mails.items() if metadata['content'] != ''}\n",
    "ham_mails = {msg_id: metadata for msg_id, metadata in ham_mails.items() if metadata['content'] != ''}\n",
    "\n",
    "print(f\"Number of spam mails: {len(spam_mails)}\")\n",
    "print(f\"Number of ham mails: {len(ham_mails)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "432cca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of spam: 0.1125\n",
      "Probability of ham: 0.8875\n"
     ]
    }
   ],
   "source": [
    "p_spam = len(spam_mails)/(len(spam_mails) + len(ham_mails))\n",
    "p_ham = len(ham_mails)/(len(spam_mails) + len(ham_mails))\n",
    "print(f\"Probability of spam: {p_spam}\")\n",
    "print(f\"Probability of ham: {p_ham}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e775adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_iterator = list(spam_mails.items())\n",
    "ham_iterator = list(ham_mails.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ff385c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "spam_word_dict = {}\n",
    "ham_word_dict = {}\n",
    "\n",
    "spam_word_dict = dict(Counter(\n",
    "    word.lower()\n",
    "    for _, metadata_dict in spam_iterator\n",
    "    for word in metadata_dict['content'].split()\n",
    "))\n",
    "\n",
    "ham_word_dict = dict(Counter(\n",
    "    word.lower()\n",
    "    for _, metadata_dict in ham_iterator\n",
    "    for word in metadata_dict['content'].split()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2bb0222",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_word_count = dict(sorted(spam_word_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "ham_word_count = dict(sorted(ham_word_dict.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e20cfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in spam: 10446\n",
      "Total words in ham: 45392\n",
      "Vocabulary size (Unique words only from each set of Ham and Spam): 10199\n"
     ]
    }
   ],
   "source": [
    "total_words_in_spam = sum(spam_word_count.values())\n",
    "total_words_in_ham = sum(ham_word_count.values())\n",
    "vocab = set(list(spam_word_count.keys()) + list(ham_word_count.keys()))\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Total words in spam: {total_words_in_spam}\")\n",
    "print(f\"Total words in ham: {total_words_in_ham}\")\n",
    "print(f\"Vocabulary size (Unique words only from each set of Ham and Spam): {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b89b63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_smoothing_factor = 1\n",
    "epsilon = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9eccf5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFNaiveBayesClassifier:\n",
    "    def __init__(self, spam_word_count, ham_word_count, p_spam, p_ham, total_words_in_spam, total_words_in_ham, vocab_size, laplace_smoothing_factor):\n",
    "        self.spam_word_count = spam_word_count\n",
    "        self.ham_word_count = ham_word_count\n",
    "        self.p_spam = p_spam\n",
    "        self.p_ham = p_ham\n",
    "        self.total_words_in_spam = total_words_in_spam\n",
    "        self.total_words_in_ham = total_words_in_ham\n",
    "        self.vocab_size = vocab_size\n",
    "        self.laplace_smoothing_factor = laplace_smoothing_factor\n",
    "    \n",
    "    def get_word_probability(self,word,class_word_count_dict,total_words_in_class):\n",
    "        \"\"\"Calculate the P(word|Class) with laplace smoothing\"\"\"\n",
    "        word_count = class_word_count_dict.get(word, 0)\n",
    "        probability = (word_count + self.laplace_smoothing_factor)/(total_words_in_class + self.laplace_smoothing_factor*self.vocab_size)\n",
    "        return probability\n",
    "    \n",
    "    def get_word_probability_total(self, word):\n",
    "        \"\"\"Calculate the P(word) occuring in the training set (with laplace smoothing)\"\"\"\n",
    "        spam_probability = self.get_word_probability(word, self.spam_word_count, self.total_words_in_spam)\n",
    "        ham_probability = self.get_word_probability(word, self.ham_word_count, self.total_words_in_ham)\n",
    "        return spam_probability*self.p_spam + ham_probability*self.p_ham\n",
    "    \n",
    "    def classification_probability(self, email_content):\n",
    "        \"\"\"Classify the email content as spam or ham\"\"\"\n",
    "        words = email_content.lower().split()\n",
    "        \n",
    "        # probability_spam_given_words = self.p_spam\n",
    "        # probability_ham_given_words = self.p_ham\n",
    "        \n",
    "        log_probability_spam = math.log(self.p_spam)\n",
    "        log_probability_ham = math.log(self.p_ham)\n",
    "        \n",
    "        for word in words:\n",
    "            probability_word_given_spam = self.get_word_probability(word,self.spam_word_count,self.total_words_in_spam)\n",
    "            probability_word_given_ham = self.get_word_probability(word,self.ham_word_count,self.total_words_in_ham)\n",
    "            \n",
    "            # probability_spam_given_words *= probability_word_given_spam\n",
    "            # probability_ham_given_words *= probability_word_given_ham\n",
    "            \n",
    "            log_probability_spam += math.log(probability_word_given_spam)\n",
    "            log_probability_ham += math.log(probability_word_given_ham)\n",
    "            \n",
    "        # Normalize the probabilities\n",
    "        # total_probability = probability_spam_given_words + probability_ham_given_words\n",
    "        max_log_probability = max(log_probability_spam, log_probability_ham)\n",
    "        \n",
    "        log_probability_spam -= max_log_probability\n",
    "        log_probability_ham -= max_log_probability\n",
    "        probability_spam_given_words = math.exp(log_probability_spam)\n",
    "        probability_ham_given_words = math.exp(log_probability_ham)\n",
    "        \n",
    "        total_probability = probability_spam_given_words + probability_ham_given_words\n",
    "        \n",
    "        #Final probabilities\n",
    "        probability_spam_given_words /= total_probability\n",
    "        probability_ham_given_words /= total_probability\n",
    "        \n",
    "        return {\n",
    "            'spam_probability': probability_spam_given_words,\n",
    "            'ham_probability': probability_ham_given_words\n",
    "        }\n",
    "        \n",
    "    def classify(self, email_content):\n",
    "        \"\"\"Classify the email content as spam or ham\"\"\"\n",
    "        probabilities = self.classification_probability(email_content)\n",
    "        if probabilities['spam_probability'] > probabilities['ham_probability']:\n",
    "            return 'spam'\n",
    "        else:\n",
    "            return 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "18a52880",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_classifier = TFNaiveBayesClassifier(spam_word_count, ham_word_count, p_spam, p_ham, total_words_in_spam, total_words_in_ham, vocab_size, laplace_smoothing_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c2b4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID: 1977c01f5cb0dd2e, Classification: spam, Probabilities: 1.0000 (spam), 0.0000 (ham)\n",
      "Message ID: 19779781bb917411, Classification: spam, Probabilities: 1.0000 (spam), 0.0000 (ham)\n"
     ]
    }
   ],
   "source": [
    "for msg_id, metadata in list(spam_iterator)[:2]:\n",
    "    classification = custom_classifier.classify(metadata['content'])\n",
    "    classification_probabilities = custom_classifier.classification_probability(metadata['content'])\n",
    "    print(f\"Message ID: {msg_id}, Classification: {classification}, Probabilities: {classification_probabilities['spam_probability']:.4f} (spam), {classification_probabilities['ham_probability']:.4f} (ham)\")\n",
    "    if classification != 'spam':\n",
    "        print(f\"False negative detected: {msg_id} classified as {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2bbc215a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID: 197a7d4e580868d4, Classification: ham, Probabilities: {'spam_probability': 1.1015829438272598e-96, 'ham_probability': 1.0}\n",
      "Message ID: 197a78f9bed58bbc, Classification: ham, Probabilities: {'spam_probability': 1.5645061429012604e-31, 'ham_probability': 1.0}\n",
      "Message ID: 197a78ed8cc0013c, Classification: ham, Probabilities: {'spam_probability': 0.0, 'ham_probability': 1.0}\n",
      "Message ID: 197a778de17fefb9, Classification: ham, Probabilities: {'spam_probability': 3.578927961067373e-74, 'ham_probability': 1.0}\n",
      "Message ID: 197a75f39fa640fc, Classification: ham, Probabilities: {'spam_probability': 6.277535012127772e-32, 'ham_probability': 1.0}\n",
      "Message ID: 197a6c8f1453cbfc, Classification: ham, Probabilities: {'spam_probability': 6.466990656256815e-30, 'ham_probability': 1.0}\n",
      "Message ID: 197a644902ac8cf2, Classification: ham, Probabilities: {'spam_probability': 1.9475170424249584e-44, 'ham_probability': 1.0}\n",
      "Message ID: 197a64194abe7155, Classification: ham, Probabilities: {'spam_probability': 2.14504e-319, 'ham_probability': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for msg_id, metadata in list(ham_iterator)[:8]:\n",
    "    classification = custom_classifier.classify(metadata['content'])\n",
    "    classification_probabilities = custom_classifier.classification_probability(metadata['content'])\n",
    "    print(f\"Message ID: {msg_id}, Classification: {classification}, Probabilities: {classification_probabilities}\")\n",
    "    if classification != 'ham':\n",
    "        print(f\"False positive detected: {msg_id} classified as {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "31d4ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have inlcuded many optimizations in this code, such as:\n",
    "## 1. Using log probabilities to avoid underflow issues with very small probabilities which was resulting in NaN values and thus ZeroDivisionError.\n",
    "## 2. Subtract the maximum log probability to avoid overflow issues with very large probabilities.\n",
    "## 3. We have not used epsilon anywhere in this code, as we are using log probabilities which avoids the underflow issues.\n",
    "\n",
    "# This code is a simple implementation of a Naive Bayes classifier for spam detection using term frequency only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f8609ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another interesting thing to note is that, the spam classification is almost perfect, while the ham classification sometimes provides higher spam probabilities than what spam emails have in ham probabilities, i.e. there is a sense of spam being detected in ham emails too, but not as much as spam emails being detected as spam. This is because the spam emails have a lot of common words which are not present in ham emails, thus making it easier to classify them as spam.\n",
    "# One can conclude that some of the ham emails are actually spam, but they are not classified as spam because they do not have enough common words with the spam emails. This is a limitation of the Naive Bayes classifier, as it assumes that the words are independent of each other, which is not always the case in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f94bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naive_bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
